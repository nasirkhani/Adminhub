## ‚öôÔ∏è Overview ‚Äî Where ‚ÄúConcurrency‚Äù Appears in Airflow

Airflow has **three main levels** of concurrency control:

| Level                             | Config / Parameter                                                         | Scope                      | Controls                                                                             |
| --------------------------------- | -------------------------------------------------------------------------- | -------------------------- | ------------------------------------------------------------------------------------ |
| üß† **Global**                     | `parallelism` (in `airflow.cfg`)                                           | Whole Airflow system       | Max *total* number of task instances (TIs) that can run across all DAGs, all workers |
| üìä **DAG-level**                  | `max_active_tasks` / `max_active_runs` / `concurrency` (in DAG definition) | Each DAG                   | Limits how many TIs from that DAG can run simultaneously                             |
| ‚öôÔ∏è **Worker-level**               | `worker_concurrency` (in `[celery]` section of `airflow.cfg`)              | Each Celery worker process | Max number of tasks that each Celery worker can execute concurrently                 |
| üíª **Executor slots (scheduler)** | `max_tis_per_query`, `scheduler_heartbeat_sec`                             | Scheduler ‚Üí DB load tuning | Limits how many TIs are fetched from DB per cycle                                    |
| üß© **Task-level**                 | `pool` or `task_concurrency` (in operator)                                 | Individual tasks           | Limits how many *instances* of this task ID can run in parallel                      |

---

## üß± Let‚Äôs explain each clearly with examples

### 1. **Global: `parallelism` (in `airflow.cfg`)**

```ini
[core]
parallelism = 32
```

* This limits the total number of **task instances** that Airflow can run *system-wide*, across all DAGs and workers.
* If set too low, you can have many tasks ‚Äúqueued‚Äù forever even though workers are idle.
* Think of this as the **global concurrency cap**.

‚úÖ For your cluster (2 workers √ó 4 concurrency each = 8 real parallel slots),
a safe value is 32‚Äì64.

---

### 2. **Worker-level: `worker_concurrency` (in `[celery]`)**

```ini
[celery]
worker_concurrency = 4
```

* This controls how many *Python processes per Celery worker* can run tasks in parallel.
* Each worker VM runs up to that many tasks concurrently.

üß† Example:

* You have two workers (`celery-1`, `celery-2`)
* Each has `worker_concurrency = 4`
  ‚Üí You can theoretically run **8 parallel tasks**.

If you run 9+ tasks, the extra ones stay in **queued** state until a slot opens.

‚ö†Ô∏è If `parallelism` (global) is lower than `worker_concurrency √ó workers`, you‚Äôll still get a bottleneck ‚Äî tasks queue up even if worker slots are free.

---

### 3. **DAG-level: `concurrency` and `max_active_runs`**

Inside a DAG file:

```python
dag = DAG(
    'my_dag',
    concurrency=4,
    max_active_runs=2,
)
```

* `concurrency`: max number of *tasks from this DAG* that can run at once, across all DAG runs.
* `max_active_runs`: max number of DAG runs that can execute concurrently (e.g., today + yesterday).

üß† Example:
If your DAG runs every 5 minutes but takes 10 minutes to finish:

* `max_active_runs=1` ‚Üí new run waits until previous finishes
* `max_active_runs=2` ‚Üí you can have 2 overlapping runs
* `concurrency=3` ‚Üí within all runs, only 3 tasks total can execute at once

---

### 4. **Task-level: `task_concurrency`**

You can set per-task limits to avoid overlapping instances:

```python
BashOperator(
    task_id='check_postgresql_3_patroni',
    task_concurrency=1,
    ...
)
```

‚Üí prevents more than 1 instance of that specific task from running simultaneously, even across DAG runs.

---

### 5. **Pools**

Pools are logical groups of slots you can assign to tasks:

```bash
airflow pools set postgres_check_pool 2 "Pool for PostgreSQL checks"
```

and in DAG:

```python
BashOperator(pool='postgres_check_pool')
```

‚Üí ensures only 2 of these tasks run at once, even if there are many worker slots free.

---

## üí£ How Misconfigured Concurrency Can Cause ‚ÄúQueued ‚Üí Failed‚Äù Problems

Here‚Äôs the subtle but important part related to your error:

### ‚ùå Scenario

You have:

```ini
[core]
parallelism = 16

[celery]
worker_concurrency = 4
```

and two workers (‚Üí 8 task slots total).

Now your scheduler tries to queue 20 tasks because DAG concurrency allows it.
However:

* 16 tasks get submitted fine.
* 4 tasks remain in **queued** because the global cap (16) is hit.
* Scheduler marks them as ‚Äúqueued‚Äù in DB.
* Celery (or another scheduler) eventually tries to pick one up again, but it‚Äôs now stale or expired.
* Airflow detects a mismatch:
  ‚ÄúTask says queued, executor says finished (failed). Was it killed externally?‚Äù

üí• That‚Äôs **exactly your log line.**

---

## ‚úÖ How to Fix / Tune for Your Cluster

For your architecture (2 schedulers, 2 workers, 4 slots each):

| Setting                       | Suggested Value                            | Why                                                                |
| ----------------------------- | ------------------------------------------ | ------------------------------------------------------------------ |
| `[core] parallelism`          | `64`                                       | Gives headroom for HA schedulers, avoids system-wide throttle      |
| `[celery] worker_concurrency` | `4`‚Äì`6`                                    | 4 is fine per 2 GB RAM; can increase slightly if lightweight tasks |
| `concurrency` in DAGs         | `4`‚Äì`8`                                    | Safe default per DAG to prevent oversubscription                   |
| `max_active_runs`             | `1` or `2`                                 | For monitoring DAGs like `ha_service_health_monitor`, use 1        |
| `task_concurrency`            | Only if specific task should never overlap | e.g., a health check that must run once at a time                  |

---

### Example: good configuration for your monitoring DAG

```python
dag = DAG(
    'ha_service_health_monitor',
    schedule_interval='*/5 * * * *',
    max_active_runs=1,
    concurrency=4,
    catchup=False,
)
BashOperator(
    task_id='check_postgresql_3_patroni',
    bash_command='check_pg_node.sh 3',
    task_concurrency=1,
    pool='postgres_check_pool',
    retries=2,
    retry_delay=timedelta(minutes=1),
)
```

---

## üîé TL;DR ‚Äî Quick Reference

| Setting              | Scope  | Typical Range  | Applies To         | Notes                  |
| -------------------- | ------ | -------------- | ------------------ | ---------------------- |
| `parallelism`        | Global | 32‚Äì128         | Whole Airflow      | Total running tasks    |
| `worker_concurrency` | Worker | 2‚Äì8 per worker | Each Celery worker | OS resources dependent |
| `concurrency`        | DAG    | 4‚Äì8            | Tasks within DAG   | Prevent DAG flood      |
| `max_active_runs`    | DAG    | 1‚Äì2            | DAG runs           | Avoid overlap          |
| `task_concurrency`   | Task   | 1              | Individual task    | For singleton tasks    |

---

### ‚úÖ Practical tip

If you often see `task stuck in queued` or `task says queued but finished`, **raise `parallelism` first**, then check Celery logs for worker slot saturation:

```bash
airflow celery inspect active
airflow celery inspect reserved
airflow celery inspect stats
```

---

