# گزارش پیشرفت پروژه: پیاده‌سازی Apache Airflow برای خودکارسازی تسک‌های اجرایی

<div dir="rtl">

## 1. مقدمه
در راستای بهینه‌سازی و خودکارسازی اجرای تعداد زیادی از اسکریپت‌های تکراری و متوالی بر روی سرورهای ریموت، پروژه‌ای با هدف پیاده‌سازی و بهره‌برداری از Apache Airflow آغاز شد. با توجه به افزایش پیچیدگی تسک‌ها و تعداد بالای سرورهای هدف، خطر بروز خطای انسانی، تاخیر در اجرا و نبود پایش دقیق در فرآیندهای فعلی، استفاده از ابزارهای اتوماسیون پیشرفته ضروری به نظر می‌رسد.

## 2. دلایل انتخاب Airflow
Apache Airflow به عنوان یک ابزار قدرتمند برای تعریف، زمان‌بندی، اجرا و مانیتورینگ جریان‌های کاری (Workflows) انتخاب شد. دلایل انتخاب این ابزار شامل موارد زیر است:

- تعریف ساختارمند و گراف‌مانند (DAG) برای تسک‌ها
- قابلیت زمان‌بندی دقیق و انعطاف‌پذیر
- قابلیت اتصال به سرورهای ریموت برای اجرای دستورات
- پشتیبانی از اجراهای توزیع‌شده و مقیاس‌پذیر با استفاده از Celery
- واسط کاربری گرافیکی برای مانیتورینگ و بررسی خطاها
- سازگاری بالا با زبان پایتون و سایر ابزارهای موجود در اکوسیستم DevOps

## 3. انتخاب ابزارهای پشتیبان
- PostgreSQL به عنوان Backend Database برای ذخیره‌سازی metadata مربوط به DAGها و تسک‌ها، به علت پایداری بالا و سازگاری کامل با Airflow
- RabbitMQ به عنوان message broker برای صف‌بندی تسک‌ها و ارتباط میان کامپوننت‌ها در معماری توزیع‌شده
- Celery برای اجرای توزیع‌شده‌ی تسک‌ها روی چندین worker به صورت مقیاس‌پذیر و با عملکرد بالا

## 4. معماری و نحوه استقرار
در فاز اولیه، از محیط مجازی‌سازی (VMware) برای راه‌اندازی نمونه‌ی تست استفاده شد. این محیط شامل:

- یک ماشین برای اجرای core اجزای Airflow (Scheduler, Webserver, Worker)
- دو ماشین به عنوان هدف اجرای اسکریپت‌ها (Remote Targets)

در آینده، با گسترش پروژه به محیط عملیاتی، زیرساخت به صورت Distributed و High Availability (HA) طراحی خواهد شد، به‌طوری که هر جزء روی سرور اختصاصی با منابع مناسب اجرا گردد.

## 5. مقایسه دو معماری Airflow
در ادامه خلاصه‌ای از مزایای پیاده‌سازی Apache Airflow در دو معماری تک‌ماشینه‌ای و توزیع‌شده ارائه می‌شود:

### مزایای پیاده‌سازی Airflow به‌صورت تک‌ماشینه‌ای (Single Machine Deployment)
- سادگی در راه‌اندازی و نگهداری: همه‌ی اجزا روی یک سرور اجرا می‌شوند، نصب و پیکربندی سریع‌تر انجام می‌گیرد.
- مناسب برای تیم‌های کوچک یا پروژه‌های آزمایشی: زمانی که فقط یک نفر مسئول توسعه و نگهداری DAGهاست.
- کاهش هزینه‌های سخت‌افزاری و زیرساخت: نیاز به یک ماشین واحد
- عدم نیاز به سیستم‌های اشتراک فایل: فایل‌های DAG مستقیماً از فایل‌سیستم محلی خوانده می‌شوند.

### مزایای پیاده‌سازی Airflow به‌صورت توزیع‌شده (Distributed Architecture)
- مقیاس‌پذیری بالا: با افزودن Workerهای بیشتر، توان اجرای DAGها افزایش می‌یابد.
- تفکیک نقش‌ها و امنیت بالاتر: نقش‌ها و سطح دسترسی‌ها قابل تفکیک هستند.
- استفاده از Triggerer و Task Deferral: مناسب برای سناریوهای شامل Sensors و تسک‌های در حال انتظار
- استقلال اجزا و قابلیت مانیتورینگ بهتر: هر جزء در ماشین جداگانه با کنترل و مدیریت بهتر
- امکان استفاده از ابزارهای ابری مانند Kubernetes و Helm: برای استقرار در محیط‌های مدرن و مقیاس‌پذیر ابری

## 6. ملاحظات سخت‌افزاری در محیط تست
راه‌اندازی محیط تست با منابع محدود شامل:

- 16GB RAM
- HDD با سرعت 7200RPM
- پردازنده معمولی

به دلیل سنگینی عملیات اجرا و لاگ‌گیری روی چند VM همزمان، نیاز به RAM و I/O دیسک بالاتر وجود دارد.

طراحی محیط تست به‌گونه‌ای بوده است که بتواند حداقل نیازهای یک سناریوی واقعی را پوشش دهد، اما برای محیط عملیاتی باید زیرساخت قوی‌تری تهیه گردد.

## 7. مفاهیم کلیدی آموخته‌شده و پیاده‌سازی‌شده
- Scheduler: زمان‌بندی اجرای تسک‌ها براساس DAGهای تعریف‌شده
- Webserver: ارائه UI جهت مشاهده وضعیت DAGها، لاگ‌ها و مانیتورینگ
- Worker: اجرای تسک‌ها در معماری Celery
- Operators: ابزارهای اجرای وظایف (مانند BashOperator، PythonOperator، SSHOperator)
- Sensors: بررسی وضعیت تا آماده شدن منابع یا رویدادهای خارجی
- TaskFlow-decorated functions: روشی نوین و تابع‌محور در تعریف DAGها
- Connections: تعریف کانکشن‌های امن مانند SSH برای اتصال به سرورهای ریموت

## 8. کارهای انجام‌شده در دو هفته اخیر
- راه‌اندازی اولیه‌ی محیط تست با اجزای لازم Airflow
- بررسی و تهیه منابع سخت‌افزاری مناسب برای تست
- نصب و پیکربندی PostgreSQL، RabbitMQ، Celery و وابستگی‌های دیگر
- طراحی و تست DAGهای ابتدایی برای اجرای تسک‌های ساده روی سرورهای ریموت
- تست اتصال امن به سرورهای ریموت (دو سرور به عنوان target فعلا تعریف شده‌اند)
- مانیتورینگ اجرای تسک‌ها از طریق واسط کاربری Airflow و بررسی لاگ‌ها
- آشنایی با تنظیم زمان‌بندی تسک‌ها و اجرای وابسته به ترتیب و زمان

DAGهای فعلی بیشتر در سطح تست اولیه و بررسی امکان‌سنجی بوده‌اند و با موفقیت اجرا شده‌اند.

## 9. مزایای پیاده‌سازی Airflow به‌صورت تک‌ماشینه‌ای (Single Machine Deployment)
- **سادگی در راه‌اندازی و نگهداری**: همه‌ی اجزا (Scheduler، Webserver، Worker و Database) روی یک سرور اجرا می‌شوند و نصب و پیکربندی آن بسیار سریع و ساده است.
- **مناسب برای تیم‌های کوچک یا پروژه‌های آزمایشی**: زمانی که فقط یک نفر مسئول توسعه، استقرار و نگهداری DAGهاست، این معماری بهترین گزینه است.
- **کاهش هزینه‌های سخت‌افزاری و زیرساخت**: تنها یک ماشین نیاز است؛ هزینه‌های سرور، مانیتورینگ و شبکه کاهش می‌یابد.
- **عدم نیاز به سیستم‌های اشتراک فایل**: فایل‌های DAG مستقیماً از فایل‌سیستم محلی خوانده می‌شوند؛ نیازی به همگام‌سازی میان چند ماشین نیست.

## 10. مزایای پیاده‌سازی Airflow به‌صورت توزیع‌شده (Distributed Architecture)
- **مقیاس‌پذیری بالا**: می‌توان با افزودن Workerهای بیشتر، حجم پردازش را متناسب با نیاز افزایش داد؛ مناسب برای محیط‌های تولید (Production) و داده‌های حجیم.
- **تفکیک نقش‌ها و امنیت بالاتر**: نقش‌هایی مثل توسعه‌دهنده DAG، مدیر استقرار و اپراتور سیستم تفکیک می‌شوند؛ دسترسی به اجزای حیاتی مثل پایگاه داده یا فایل‌های DAG محدود می‌شود.
- **استقلال اجزا و قابلیت مانیتورینگ بهتر**: هر جزء مثل Scheduler، Worker و Webserver روی ماشین جداگانه اجرا می‌شود که باعث بهبود عملکرد، نگهداری و مانیتورینگ سیستم می‌شود.

## 11. برنامه‌های آینده
با توجه به حساسیت بالای محیط عملیاتی، به‌ویژه در سیستم‌های پرداخت بانکی که نیازمند پایداری، امنیت و دقت بسیار بالا در اجرای عملیات هستند، لازم است فاز تست به‌شکل جامع، ساختارمند و مرحله‌ای انجام شود. تاکنون تست‌های محدودی صرفاً با هدف بررسی زیرساخت و اجرای DAGهای ابتدایی انجام شده‌اند و هنوز وارد فاز تست جدی نشده‌ایم. برنامه‌ریزی برای ادامه‌ی مسیر به‌صورت زیر است:

### فاز 1: طراحی سناریوهای تست جامع
برای اطمینان از صحت عملکرد و آمادگی برای ورود به محیط عملیاتی، طراحی و پیاده‌سازی مجموعه‌ای از تست‌های هدفمند و قابل اندازه‌گیری ضروری است. برخی از سناریوهای کلیدی عبارت‌اند از:

- **تست صحت اجرای تسک‌ها در شرایط عادی**: اجرای DAGهایی با زنجیره‌های ساده برای اطمینان از درست اجرا شدن دستورات، اتصال‌ها، و زمان‌بندی‌ها.
- **تست تسک‌های وابسته به شرایط خارجی (Event-based)**: استفاده از Sensors برای سنجش فایل، وضعیت سرور یا پاسخ API، و بررسی رفتار سیستم در حالت‌های در انتظار (deferred).
- **تست در مواجهه با خطا (Failure Scenarios)**:
  - قطع ارتباط شبکه با سرور ریموت در حین اجرای تسک
  - عدم دسترسی به فایل یا مسیر مورد نظر
  - خطا در اجرای اسکریپت
  - بررسی اینکه آیا retryها، alertها و rollback مناسب انجام می‌شود یا خیر.
- **تست بار (Load Testing)**: اجرای هم‌زمان چندین DAG و تسک روی چند سرور برای شبیه‌سازی شرایط عملیاتی سنگین و بررسی نحوه عملکرد Scheduler و Workerها.
- **تست تکرارپذیری و idempotency**: بررسی اینکه اجرای مجدد یک DAG منجر به وضعیت ناسازگار یا اشتباه نشود. این موضوع به‌ویژه در محیط‌های حساس مانند مالی بسیار حیاتی است.

### فاز 2: تحلیل و ارتقاء زیرساخت تست
با توجه به نتایج تست‌های اولیه، مشخص شد که سخت‌افزار فعلی در محیط تست (با رم ۱۶ گیگ و هارد HDD) پاسخگوی نیازهای اجرای DAGهای هم‌زمان روی چند ماشین هدف نیست. بنابراین در برنامه است:

- ارتقاء سخت‌افزار محیط تست (استفاده از SSD، افزایش RAM، جداسازی Worker و Scheduler در ماشین‌های مجزا)
- شبیه‌سازی ساختار نهایی محیط Production برای تست دقیق‌تر و کاهش تفاوت محیط‌ها
- اضافه کردن سرورهای هدف بیشتر با شرایط متنوع (شبکه کند، پاسخ‌گویی متفاوت، بار سنگین و ...)

### فاز 3: پیاده‌سازی مانیتورینگ پیشرفته
در حال حاضر، صرفاً از UI داخلی Airflow برای مشاهده DAGها و لاگ‌ها استفاده می‌شود. در آینده، برای افزایش قابلیت پایش و هشداردهی:

- راه‌اندازی Grafana + Prometheus برای مانیتورینگ لحظه‌ای
- پایش متریک‌هایی مانند:
  - مدت زمان اجرای تسک‌ها
  - تعداد تسک‌های شکست‌خورده/موفق
  - وضعیت منابع سرورهای Worker
  - حجم لاگ‌ها و تعداد retryها
- تعریف Alert برای تسک‌های حیاتی (مثلاً ارسال ایمیل یا پیام فوری در صورت عدم موفقیت یک DAG کلیدی)

### فاز 4: بررسی امنیت و کنترل دسترسی
در پروژه‌هایی با اهمیت عملیاتی و امنیتی بالا مانند سامانه‌های پرداخت بانکی، اعمال سیاست‌های سخت‌گیرانه امنیتی ضروری است:

- تعیین Role و دسترسی کاربران در UI
- جداسازی دسترسی به فایل‌ها و رمزهای اتصال (Connection Secrets)
- بررسی امکان رمزنگاری اتصالات و داده‌ها
- نگهداری امن رمزها و کلید ها

### فاز 5: آماده‌سازی برای معماری توزیع‌شده و عملیاتی
پس از عبور از مراحل تست و حصول اطمینان از عملکرد درست DAGها، زیرساخت برای مهاجرت به معماری توزیع‌شده آماده خواهد شد:

- استقرار اجزای Airflow به صورت جداگانه (Scheduler، Webserver، Workerها، Triggerer) روی ماشین‌های مختلف
- استفاده از message broker واقعی (RabbitMQ) در بستر شبکه‌ای پایدار

گذر از مرحله تست سطحی به مرحله تست جدی و دقیق، نیازمند زمان، حوصله و همکاری نزدیک تیم‌های زیرساخت، امنیت و توسعه است. با توجه به ماهیت حساس عملیات در سیستم‌های پرداخت بانکی، پیشنهاد می‌شود فاز تست و آماده‌سازی حداقل در سه مرحله (تست DAGهای ساده، تست بار، تست خطا و امنیت) تا رسیدن به بلوغ عملیاتی ادامه پیدا کند.

مطمئناً سرمایه‌گذاری زمانی و فنی در این مرحله، مانع بروز خطا در زمان اجرای واقعی خواهد شد و باعث افزایش اعتماد، پایداری و کیفیت در اجرای خودکار وظایف مهم عملیاتی خواهد بود.

</div>
