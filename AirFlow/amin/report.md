
# گزارش پیشرفت پروژه: پیاده‌سازی Apache Airflow برای خودکارسازی تسک‌های اجرایی

## 1. مقدمه

برای بهینه‌سازی و خودکارسازی اجرای تعداد زیادی از **اسکریپت‌های** تکراری و متوالی روی سرورهای ریموت، پروژه‌ای با هدف پیاده‌سازی و بهره‌برداری از سامانه Apache Airflow آغاز شد. با افزایش پیچیدگی تسک‌ها و تعداد بالای سرورهای هدف، خطر بروز خطای انسانی، تاخیر در اجرا و نبود پایش دقیق در فرآیندهای فعلی افزایش یافت. به همین دلیل استفاده از ابزارهای اتوماسیون پیشرفته ضروری است.

## 2. دلایل انتخاب ابزار Airflow

ابزار Apache Airflow به دلیل توانمندی‌های خاص در تعریف، زمان‌بندی، اجرا و نظارت بر جریان‌های کاری (Workflows) انتخاب شد. مهم‌ترین دلایل این انتخاب عبارتند از:

* امکان تعریف ساختارمند و گراف‌مانند (DAG) برای تسک‌ها
* قابلیت زمان‌بندی دقیق و انعطاف‌پذیر
* امکان اتصال به سرورهای ریموت جهت اجرای دستورات
* پشتیبانی از اجراهای توزیع‌شده و مقیاس‌پذیر با استفاده از Celery
* واسط کاربری گرافیکی برای نظارت و بررسی خطاها
* سازگاری بالا با زبان برنامه‌نویسی پایتون و سایر ابزارهای اکوسیستم DevOps

## 3. ابزارهای پشتیبان انتخاب شده

برای مدیریت داده‌ها و ارتباط بین اجزای پروژه از ابزارهای زیر بهره گرفته شده است:

* پایگاه داده PostgreSQL به عنوان بانک اطلاعاتی Backend جهت ذخیره‌سازی metadata مربوط به DAGها و تسک‌ها، به دلیل پایداری و سازگاری بالا با Airflow
* سامانه RabbitMQ به عنوان پیام‌رسان (Message Broker) برای صف‌بندی تسک‌ها و ارتباط میان اجزا در معماری توزیع‌شده
* ابزار Celery برای اجرای توزیع‌شده تسک‌ها روی چندین Worker به صورت مقیاس‌پذیر و با عملکرد بهینه

## 4. معماری و نحوه استقرار اولیه

در فاز ابتدایی پروژه، محیط تست بر بستر مجازی‌سازی VMware راه‌اندازی شد که شامل موارد زیر است:

* یک سرور جهت اجرای اجزای اصلی Airflow مانند Scheduler، Webserver و Worker
* دو سرور به عنوان هدف اجرای اسکریپت‌ها (Remote Targets)

با گسترش پروژه، معماری به صورت توزیع‌شده و با قابلیت High Availability طراحی خواهد شد تا هر جزء روی سرور اختصاصی با منابع مناسب اجرا گردد.
## 5. مزایای پیاده‌سازی Airflow در معماری توزیع‌شده

در معماری توزیع‌شده، اجزای اصلی سامانه شامل بخش زمان‌بندی، اجراکننده وظایف، واسط کاربری و پایگاه داده متادیتا هرکدام روی سرورهای جداگانه اجرا می‌شوند. این ساختار مزایای متعددی دارد که آن را به انتخابی مناسب برای محیط‌های عملیاتی با حجم کاری بالا تبدیل می‌کند.

### مشخصات این نوع معماری

* اجرای اجزای اصلی شامل Scheduler، Worker، Webserver و پایگاه داده متادیتا روی ماشین‌های مستقل
* استفاده از پایگاه داده‌هایی مانند PostgreSQL یا MySQL در سطح خوشه‌ای برای افزایش دسترس‌پذیری
* بهره‌گیری از پیام‌رسان‌هایی مانند RabbitMQ یا Redis برای مدیریت صف وظایف در معماری مبتنی بر Celery
* امکان استفاده از CeleryExecutor برای توزیع وظایف بین Workerها، یا KubernetesExecutor برای اجرای وظایف به‌صورت داینامیک در محیط‌های مبتنی بر Kubernetes
* انجام تحلیل DAGها توسط Scheduler و ارسال تسک‌ها به Workerها برای اجرا

### موارد کاربرد مناسب

این معماری مناسب سناریوهایی با ویژگی‌های زیر است:

* محیط‌های عملیاتی (Production) که تعداد زیادی وظیفه به‌صورت هم‌زمان اجرا می‌شوند
* پروژه‌هایی که نیاز به مقیاس‌پذیری، در دسترس بودن بالا و تحمل خطا دارند
* تیم‌هایی که وظایف متنوعی با نیازهای پردازشی سنگین یا وابسته به GPU اجرا می‌کنند

### مزایای اصلی

* **مقیاس‌پذیری افقی:** امکان افزودن Workerهای جدید برای افزایش ظرفیت سیستم
* **تحمل خطا بالا:** اختلال در یکی از اجزا باعث از کار افتادن کل سیستم نمی‌شود
* **ایزوله‌سازی منابع:** اجزای مستقل می‌توانند با تنظیمات و منابع اختصاصی اجرا شوند که به بهبود امنیت و بهره‌وری منجر می‌شود

### چالش‌ها و معایب

* **پیچیدگی در استقرار:** نیازمند پیکربندی دقیق اجزای متنوع و ارتباطات بین آن‌ها
* **افزایش هزینه‌های نگهداری:** به دلیل جدا بودن اجزا، مانیتورینگ و پشتیبانی از سیستم دشوارتر است
* **احتمال بروز تأخیر:** ارتباط بین اجزای مختلف ممکن است منجر به تأخیرهای جزئی در اجرای تسک‌ها شود


## 6. ملاحظات سخت‌افزاری در محیط تست

محیط تست فعلی با منابع زیر راه‌اندازی شده است:

* حافظه رم 16 گیگابایت
* هارد دیسک با سرعت 7200 دور بر دقیقه
* پردازنده core i5 8400

با توجه به عملیات سنگین اجرا و لاگ‌گیری روی چند ماشین مجازی، نیاز به افزایش RAM و بهبود I/O دیسک احساس می‌شود. محیط تست فعلی حداقل نیازهای سناریوی واقعی را پوشش نمی‌دهد اما برای تست محیط عملیاتی به زیرساخت قوی‌تری نیاز است.

## 7. مفاهیم کلیدی آموخته شده و پیاده‌سازی‌شده

در پروژه، مفاهیم و اجزای زیر بررسی و پیاده‌سازی شده‌اند:

* بخش زمان‌بندی وظایف که بر اساس نمودارهای DAG عمل می‌کند
* بررسی واسط کاربری جهت مشاهده وضعیت اجرای DAGها، لاگ‌ها و انجام نظارت
* اجرای وظایف در بخش Worker در معماری Celery
* استفاده از ابزارهای اجرای تسک ها مانند اجرای دستورات Bash، کدهای پایتون و اتصال SSH
* بهره‌گیری از سنسور ها برای بررسی وضعیت منابع یا رویدادهای خارجی
* تعریف کد ها به روش functional برای ساختاردهی بهتر DAGها
* ایجاد اتصالات امن برای ارتباط ایمن با سرورهای ریموت

## 8. کارهای انجام شده در دو هفته اخیر

فعالیت‌های انجام شده به شرح زیر است:

* راه‌اندازی اولیه محیط تست با اجزای اصلی Airflow
* بررسی و تأمین منابع سخت‌افزاری مناسب تست
* نصب و پیکربندی PostgreSQL، RabbitMQ، Celery و وابستگی‌های مرتبط
* طراحی و تست DAGهای ساده برای اجرای تسک‌ها روی سرورهای ریموت
* اطمینان از اتصال امن به سرورهای هدف (فعلاً دو سرور تعریف شده)
* نظارت بر اجرای تسک‌ها از طریق واسط کاربری و بررسی لاگ‌ها
* آشنایی با تنظیم زمان‌بندی و اجرای وابسته تسک‌ها

## 9. برنامه‌های آینده

با توجه به حساسیت بالای محیط عملیاتی، به ویژه در سامانه‌های پرداخت بانکی که نیازمند پایداری، امنیت و دقت بالایی هستند، برنامه‌ریزی برای فازهای بعدی به صورت زیر انجام شده است:

### فاز اول: طراحی سناریوهای تست جامع

هدف اطمینان از عملکرد صحیح و آمادگی برای محیط عملیاتی است. سناریوهای کلیدی عبارتند از:

* بررسی صحت اجرای تسک‌ها در شرایط عادی با DAGهای ساده
* تست تسک‌های وابسته به رویدادها و شرایط خارجی با استفاده از سنسورها
* بررسی رفتار سیستم در مواجهه با خطاها مانند قطع ارتباط شبکه، عدم دسترسی به فایل یا خطا در اسکریپت‌ها و اطمینان از اجرای عملیات retry و alert
* تست بار با اجرای هم‌زمان چندین DAG و تسک روی چندین سرور
* اطمینان از تکرارپذیری و ایمن بودن اجرای مجدد DAGها (idempotency)

### فاز دوم: تحلیل و ارتقاء زیرساخت تست

باتوجه به محدودیت‌های سخت‌افزاری فعلی، برنامه ارتقاء شامل موارد زیر است:

* استفاده از حافظه SSD، افزایش RAM و تفکیک Worker و Scheduler روی ماشین‌های جداگانه
* شبیه‌سازی دقیق‌تر محیط Production برای کاهش تفاوت‌ها
* افزودن سرورهای هدف با شرایط شبکه و بار متنوع

### فاز سوم: پیاده‌سازی مانیتورینگ پیشرفته

برای افزایش پایش و هشداردهی، برنامه راه‌اندازی ابزارهایی مانند Grafana و Prometheus در دستور کار است که موارد زیر را رصد می‌کنند:

* مدت زمان اجرای تسک‌ها
* تعداد تسک‌های موفق و شکست‌خورده
* وضعیت منابع سرورهای Worker
* حجم لاگ‌ها و تعداد عملیات retry
* تعریف هشدار برای تسک‌های حیاتی به صورت ارسال ایمیل یا پیام فوری

### فاز چهارم: بررسی امنیت و کنترل دسترسی

در پروژه‌های با اهمیت عملیاتی بالا، سیاست‌های امنیتی شامل موارد زیر لحاظ خواهد شد:

* تعیین نقش‌ها و سطح دسترسی کاربران در واسط کاربری
* جداسازی دسترسی به فایل‌ها و رمزهای اتصال
* بررسی رمزنگاری داده‌ها و اتصالات
* نگهداری امن کلیدها و رمزها

### فاز پنجم: آماده‌سازی برای معماری توزیع‌شده و عملیاتی

پس از تکمیل تست‌ها و اطمینان از عملکرد صحیح، زیرساخت به سمت معماری توزیع‌شده حرکت خواهد کرد:

* استقرار جداگانه اجزای اصلی بر روی ماشین‌های مختلف
* استفاده از پیام‌رسان (Message Broker) واقعی و پایدار

ادامه تست‌ها به صورت ساختارمند و مرحله‌ای اهمیت فراوانی دارد تا از بروز خطا در محیط عملیاتی جلوگیری شود و پایداری و کیفیت اجرای وظایف مهم تضمین گردد.


